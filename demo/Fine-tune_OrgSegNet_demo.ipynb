{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yUVtmn3Iq3WA"
   },
   "source": [
    "### Create a config file\n",
    "First, we read an initial config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wwnj9tRzqX_A"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "from mmengine import Config\n",
    "cfg = Config.fromfile(r'../configs/OrgSegNet/OrgSeg_PlantCell_768x512.py')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1y2oV5w97jQo"
   },
   "source": [
    "In the next step, we need to modify the config for the training. To accelerate the process, we finetune the model from trained weights.\n",
    "<br>\n",
    "\n",
    "Since the given config is used to train OrgSegNet on the PlantCell dataset, we need to modify it accordingly for our new dataset.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyKnYC1Z7iCV",
    "outputId": "6195217b-187f-4675-994b-ba90d8bb3078"
   },
   "outputs": [],
   "source": [
    "# Since we use only one GPU, BN is used instead of SyncBN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
    "\n",
    "# Define the batch_size for train_dataloader\\test_dataloader\\val_dataloader\n",
    "cfg.train_dataloader.batch_size = 2\n",
    "cfg.test_dataloader.batch_size = 1\n",
    "cfg.val_dataloader.batch_size = 1\n",
    "\n",
    "# We should define the data_root of new dataset\n",
    "# Please make sure the dataset is properly structured according the the guidelines.\n",
    "data_root = r'FinetuneDataset001'\n",
    "img_dir = 'image'\n",
    "ann_dir = 'label'\n",
    "\n",
    "cfg.train_dataloader.dataset.data_root = data_root\n",
    "cfg.train_dataloader.dataset.data_prefix = dict(img_path=img_dir, seg_map_path=ann_dir)\n",
    "cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n",
    "cfg.train_dataloader.dataset.ann_file = 'splits/train.txt'\n",
    "\n",
    "\n",
    "cfg.val_dataloader.dataset.data_root = data_root\n",
    "cfg.val_dataloader.dataset.data_prefix = dict(img_path=img_dir, seg_map_path=ann_dir)\n",
    "cfg.val_dataloader.dataset.pipeline = cfg.test_pipeline\n",
    "cfg.val_dataloader.dataset.ann_file = 'splits/val.txt'\n",
    "\n",
    "\n",
    "cfg.test_dataloader.dataset.data_root = data_root\n",
    "cfg.test_dataloader.dataset.data_prefix = dict(img_path=img_dir, seg_map_path=ann_dir)\n",
    "cfg.test_dataloader.dataset.pipeline = cfg.test_pipeline\n",
    "cfg.test_dataloader.dataset.ann_file = 'splits/test.txt'\n",
    "\n",
    "# Load the pretrained weights\n",
    "cfg.load_from = \"../checkpoints/OrgSegNet_iter_Version1.pth\"\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './work_dirs/finetune001'\n",
    "\n",
    "# Define the max iterations for the finetune pipline \n",
    "cfg.train_cfg.max_iters = 10000\n",
    "\n",
    "# Validation is performed every 200 iterations\n",
    "cfg.train_cfg.val_interval = 200\n",
    "\n",
    "cfg.default_hooks.logger.interval = 10\n",
    "\n",
    "# The model will be saved every 200 iterations\n",
    "cfg.default_hooks.checkpoint.interval = 200\n",
    "# save newest 3 checkpoints\n",
    "cfg.default_hooks.checkpoint.max_keep_ckpts = 3\n",
    "# save best checkpoint based mIoU\n",
    "cfg.default_hooks.checkpoint.save_best = save_best=['mIoU']\n",
    "cfg.default_hooks.checkpoint.rule = 'greater'\n",
    "\n",
    "# Set seed to facilitate reproducing the result\n",
    "cfg['randomness'] = dict(seed=0)\n",
    "# Let's have a look at the final config used for training\n",
    "# print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QWuH14LYF2gQ"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYKoSfdMF12B",
    "outputId": "422219ca-d7a5-4890-f09f-88c959942e64"
   },
   "outputs": [],
   "source": [
    "from mmengine.runner import Runner\n",
    "runner = Runner.from_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test or Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "DEkWOP-NMbc_"
   },
   "source": [
    "When the fine-tuning pipline was done, We can start the inference pipline with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we should read the newest config from the workdir.\n",
    "from mmengine import Config\n",
    "cfg = Config.fromfile(r'./demo/work_dirs/finetunetest/OrgSeg_PlantCell_768x512.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "id": "ekG__UfaH_OU",
    "outputId": "1437419c-869a-4902-df86-d4f6f8b2597a"
   },
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "from mmseg.apis import init_model, inference_model, show_result_pyplot, show_cell_pyplot\n",
    "palette = [[255, 255, 255], [174, 221, 153], [14, 205, 173], [238,137,39], [244, 97, 150]]\n",
    "\n",
    "# Read and init the model from the config and the best mIoU model (checkpoint) in the workdir.\n",
    "checkpoint_path = './demo/work_dirs/finetunetest/best_mIoU_iter_xxxxxx.pth'\n",
    "model = init_model(cfg, checkpoint_path, 'cuda:0')\n",
    "\n",
    "# Read an image for inference.\n",
    "img = mmcv.imread('./demo_images/demo2.tif')\n",
    "result = inference_model(model, img)\n",
    "plt.figure(figsize=(8, 6))\n",
    "vis_result = show_cell_pyplot(model, img, result, ogrannel=None)\n",
    "# Show the image\n",
    "plt.imshow(mmcv.bgr2rgb(vis_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MMSegmentation Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pt1.12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "0442e67aee3d9cbb788fa6e86d60c4ffa94ad7f1943c65abfecb99a6f4696c58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
